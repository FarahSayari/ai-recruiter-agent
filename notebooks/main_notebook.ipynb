{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2b7bde",
   "metadata": {},
   "source": [
    "# AI-Powered Recruitment Agent  \n",
    "### Intelligent CV Screening, Matching, and Ranking System  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ **Project Objective**\n",
    "\n",
    "The goal of this project is to develop an **AI Recruiter Agent** capable of:\n",
    "- Automatically reading and analyzing unstructured CVs.  \n",
    "- Matching candidates intelligently to job descriptions using semantic similarity.  \n",
    "- Ranking candidates based on relevance.  \n",
    "- Providing human-like explanations for each match.  \n",
    "- Reducing the manual screening time for HR professionals.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Dataset Overview**\n",
    "\n",
    "We use a Kaggle dataset containing the following key columns:  \n",
    "`ID`, `Name`, `Role`, `Transcript`, `Resume`, `Decision`, `Reason_for_decision`, `Job_Description`  \n",
    "\n",
    "For this notebook, we focus mainly on **textual columns**:  \n",
    "`Resume`, `Transcript`, and `Job_Description`, which represent the candidateâ€™s background and the job requirements.\n",
    "\n",
    "---\n",
    "\n",
    "## **Methodology: CRISP-DM Framework**\n",
    "\n",
    "| Phase | Description |\n",
    "|-------|--------------|\n",
    "| **1. Business Understanding** | Define project goals (automated candidate screening). |\n",
    "| **2. Data Understanding** | Explore dataset structure and content. |\n",
    "| **3. Data Preparation** | (Already completed) Preprocess CVs and job descriptions. |\n",
    "| **4. Modeling** | Convert text into embeddings using BERT, store vectors in Qdrant, and perform similarity-based matching. |\n",
    "| **5. Evaluation** | Rank candidates and evaluate semantic similarity results. |\n",
    "| **6. Deployment** | Build an AI Agent with LangGraph that automates the end-to-end recruitment process. |\n",
    "\n",
    "---\n",
    "\n",
    "## **Notebook Objective**\n",
    "\n",
    "This notebook focuses on **Modeling**, **Evaluation**, and **Deployment preparation**.  \n",
    "Specifically, it will:  \n",
    "1. Generate **embeddings** for CVs and job descriptions using **Sentence-BERT**.  \n",
    "2. Store embeddings and metadata in a **Qdrant vector database**.  \n",
    "3. Implement **retrieval logic** (RAG) to find the best candidates for a job.  \n",
    "4. Generate **explanations** for candidate-job matches using **Phi-3 (Ollama)**.  \n",
    "5. Prepare nodes and workflow for final **LangGraph agent integration**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a46121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sayar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sayar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src folder to path\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "# Import preprocessing functions\n",
    "from preprocessing import preprocess_dataframe, add_wordcount_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff28b065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Resume</th>\n",
       "      <th>decision</th>\n",
       "      <th>Reason_for_decision</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jasojo159</td>\n",
       "      <td>Jason Jones</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Interviewer: Good morning, Jason. It's great t...</td>\n",
       "      <td>Here's a professional resume for Jason Jones:\\...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lacked leadership skills for a senior position.</td>\n",
       "      <td>Be part of a passionate team at the forefront ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annma759</td>\n",
       "      <td>Ann Marshall</td>\n",
       "      <td>Game Developer</td>\n",
       "      <td>Interview Scene\\n\\nA conference room with a ta...</td>\n",
       "      <td>Here's a professional resume for Ann Marshall:...</td>\n",
       "      <td>select</td>\n",
       "      <td>Strong technical skills in AI and ML.</td>\n",
       "      <td>Help us build the next-generation products as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patrmc729</td>\n",
       "      <td>Patrick Mcclain</td>\n",
       "      <td>Human Resources Specialist</td>\n",
       "      <td>Interview Setting: A conference room in a medi...</td>\n",
       "      <td>Here's a professional resume for Patrick Mccla...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Insufficient system design expertise for senio...</td>\n",
       "      <td>We need a Human Resources Specialist to enhanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patrgr422</td>\n",
       "      <td>Patricia Gray</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Here's a simulated professional interview for ...</td>\n",
       "      <td>Here's a professional resume for Patricia Gray...</td>\n",
       "      <td>select</td>\n",
       "      <td>Impressive leadership and communication abilit...</td>\n",
       "      <td>Be part of a passionate team at the forefront ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amangr696</td>\n",
       "      <td>Amanda Gross</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Here's the simulated interview:\\n\\nInterviewer...</td>\n",
       "      <td>Here's a professional resume for Amanda Gross:...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lacked leadership skills for a senior position.</td>\n",
       "      <td>We are looking for an experienced E-commerce S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             Name                        Role  \\\n",
       "0  jasojo159      Jason Jones       E-commerce Specialist   \n",
       "1   annma759     Ann Marshall              Game Developer   \n",
       "2  patrmc729  Patrick Mcclain  Human Resources Specialist   \n",
       "3  patrgr422    Patricia Gray       E-commerce Specialist   \n",
       "4  amangr696     Amanda Gross       E-commerce Specialist   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  Interviewer: Good morning, Jason. It's great t...   \n",
       "1  Interview Scene\\n\\nA conference room with a ta...   \n",
       "2  Interview Setting: A conference room in a medi...   \n",
       "3  Here's a simulated professional interview for ...   \n",
       "4  Here's the simulated interview:\\n\\nInterviewer...   \n",
       "\n",
       "                                              Resume decision  \\\n",
       "0  Here's a professional resume for Jason Jones:\\...   reject   \n",
       "1  Here's a professional resume for Ann Marshall:...   select   \n",
       "2  Here's a professional resume for Patrick Mccla...   reject   \n",
       "3  Here's a professional resume for Patricia Gray...   select   \n",
       "4  Here's a professional resume for Amanda Gross:...   reject   \n",
       "\n",
       "                                 Reason_for_decision  \\\n",
       "0    Lacked leadership skills for a senior position.   \n",
       "1              Strong technical skills in AI and ML.   \n",
       "2  Insufficient system design expertise for senio...   \n",
       "3  Impressive leadership and communication abilit...   \n",
       "4    Lacked leadership skills for a senior position.   \n",
       "\n",
       "                                     Job_Description  \n",
       "0  Be part of a passionate team at the forefront ...  \n",
       "1  Help us build the next-generation products as ...  \n",
       "2  We need a Human Resources Specialist to enhanc...  \n",
       "3  Be part of a passionate team at the forefront ...  \n",
       "4  We are looking for an experienced E-commerce S...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca606006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted emails:\n",
      "0         jasonjones@email.com\n",
      "1       ann.marshall@email.com\n",
      "2    patrick.mcclain@email.com\n",
      "3       patriciagray@email.com\n",
      "4       amanda.gross@email.com\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract emails from raw text before preprocessing\n",
    "\n",
    "import re\n",
    "def extract_email_from_row(row):\n",
    "    for col in [\"Resume\"]:\n",
    "        val = row.get(col)\n",
    "        if isinstance(val, str) and val:\n",
    "            m = re.search(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", val)\n",
    "            if m:\n",
    "                return m.group(0).strip()\n",
    "    return None\n",
    "\n",
    "df_email = df.apply(extract_email_from_row, axis=1)\n",
    "print(\"Extracted emails:\")\n",
    "print(df_email.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ae361",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "**Objective:** Clean and standardize textual data from CVs, Transcripts, and Job Descriptions to prepare it for NLP tasks and AI-based candidate matching.\n",
    "\n",
    "**What we did:**\n",
    "- Converted text to lowercase to ensure consistency.\n",
    "- Removed URLs, HTML tags, and email addresses to eliminate noise.\n",
    "- Removed punctuation and special characters.\n",
    "- Tokenized text into words.\n",
    "- Removed common stopwords to focus on meaningful terms.\n",
    "- Applied lemmatization to reduce words to their base forms.\n",
    "- Calculated word counts before and after cleaning for comparison.\n",
    "\n",
    "**Why it is important:**\n",
    "- Ensures embeddings (CBOW, Skip-gram, BERT) capture meaningful information rather than irrelevant noise.\n",
    "- Reduces vocabulary size, improves model efficiency, and enhances AI agent understanding of candidate skills and qualifications.\n",
    "- Prepares the dataset for the next steps: embedding generation, similarity search, and candidate ranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205bb7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Resume</th>\n",
       "      <th>decision</th>\n",
       "      <th>Reason_for_decision</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Resume_clean</th>\n",
       "      <th>Transcript_clean</th>\n",
       "      <th>Job_Description_clean</th>\n",
       "      <th>Resume_wordcount</th>\n",
       "      <th>Resume_clean_wordcount</th>\n",
       "      <th>Transcript_wordcount</th>\n",
       "      <th>Transcript_clean_wordcount</th>\n",
       "      <th>Job_Description_wordcount</th>\n",
       "      <th>Job_Description_clean_wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jasojo159</td>\n",
       "      <td>Jason Jones</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Interviewer: Good morning, Jason. It's great t...</td>\n",
       "      <td>Here's a professional resume for Jason Jones:\\...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lacked leadership skills for a senior position.</td>\n",
       "      <td>Be part of a passionate team at the forefront ...</td>\n",
       "      <td>professional resume jason jones jason jones e ...</td>\n",
       "      <td>interviewer good morning jason great meet welc...</td>\n",
       "      <td>part passionate team forefront machine learnin...</td>\n",
       "      <td>342</td>\n",
       "      <td>264</td>\n",
       "      <td>606</td>\n",
       "      <td>339</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annma759</td>\n",
       "      <td>Ann Marshall</td>\n",
       "      <td>Game Developer</td>\n",
       "      <td>Interview Scene\\n\\nA conference room with a ta...</td>\n",
       "      <td>Here's a professional resume for Ann Marshall:...</td>\n",
       "      <td>select</td>\n",
       "      <td>Strong technical skills in AI and ML.</td>\n",
       "      <td>Help us build the next-generation products as ...</td>\n",
       "      <td>professional resume ann marshall ann marshall ...</td>\n",
       "      <td>interview scene conference room table two chai...</td>\n",
       "      <td>help u build next generation product game deve...</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>635</td>\n",
       "      <td>347</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patrmc729</td>\n",
       "      <td>Patrick Mcclain</td>\n",
       "      <td>Human Resources Specialist</td>\n",
       "      <td>Interview Setting: A conference room in a medi...</td>\n",
       "      <td>Here's a professional resume for Patrick Mccla...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Insufficient system design expertise for senio...</td>\n",
       "      <td>We need a Human Resources Specialist to enhanc...</td>\n",
       "      <td>professional resume patrick mcclain patrick mc...</td>\n",
       "      <td>interview setting conference room medium sized...</td>\n",
       "      <td>need human resource specialist enhance team te...</td>\n",
       "      <td>405</td>\n",
       "      <td>287</td>\n",
       "      <td>739</td>\n",
       "      <td>392</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patrgr422</td>\n",
       "      <td>Patricia Gray</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Here's a simulated professional interview for ...</td>\n",
       "      <td>Here's a professional resume for Patricia Gray...</td>\n",
       "      <td>select</td>\n",
       "      <td>Impressive leadership and communication abilit...</td>\n",
       "      <td>Be part of a passionate team at the forefront ...</td>\n",
       "      <td>professional resume patricia gray patricia gra...</td>\n",
       "      <td>simulated professional interview e commerce sp...</td>\n",
       "      <td>part passionate team forefront cloud computing...</td>\n",
       "      <td>319</td>\n",
       "      <td>241</td>\n",
       "      <td>843</td>\n",
       "      <td>490</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amangr696</td>\n",
       "      <td>Amanda Gross</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Here's the simulated interview:\\n\\nInterviewer...</td>\n",
       "      <td>Here's a professional resume for Amanda Gross:...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lacked leadership skills for a senior position.</td>\n",
       "      <td>We are looking for an experienced E-commerce S...</td>\n",
       "      <td>professional resume amanda gross amanda gross ...</td>\n",
       "      <td>simulated interview interviewer good morning a...</td>\n",
       "      <td>looking experienced e commerce specialist join...</td>\n",
       "      <td>357</td>\n",
       "      <td>274</td>\n",
       "      <td>585</td>\n",
       "      <td>335</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             Name                        Role  \\\n",
       "0  jasojo159      Jason Jones       E-commerce Specialist   \n",
       "1   annma759     Ann Marshall              Game Developer   \n",
       "2  patrmc729  Patrick Mcclain  Human Resources Specialist   \n",
       "3  patrgr422    Patricia Gray       E-commerce Specialist   \n",
       "4  amangr696     Amanda Gross       E-commerce Specialist   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  Interviewer: Good morning, Jason. It's great t...   \n",
       "1  Interview Scene\\n\\nA conference room with a ta...   \n",
       "2  Interview Setting: A conference room in a medi...   \n",
       "3  Here's a simulated professional interview for ...   \n",
       "4  Here's the simulated interview:\\n\\nInterviewer...   \n",
       "\n",
       "                                              Resume decision  \\\n",
       "0  Here's a professional resume for Jason Jones:\\...   reject   \n",
       "1  Here's a professional resume for Ann Marshall:...   select   \n",
       "2  Here's a professional resume for Patrick Mccla...   reject   \n",
       "3  Here's a professional resume for Patricia Gray...   select   \n",
       "4  Here's a professional resume for Amanda Gross:...   reject   \n",
       "\n",
       "                                 Reason_for_decision  \\\n",
       "0    Lacked leadership skills for a senior position.   \n",
       "1              Strong technical skills in AI and ML.   \n",
       "2  Insufficient system design expertise for senio...   \n",
       "3  Impressive leadership and communication abilit...   \n",
       "4    Lacked leadership skills for a senior position.   \n",
       "\n",
       "                                     Job_Description  \\\n",
       "0  Be part of a passionate team at the forefront ...   \n",
       "1  Help us build the next-generation products as ...   \n",
       "2  We need a Human Resources Specialist to enhanc...   \n",
       "3  Be part of a passionate team at the forefront ...   \n",
       "4  We are looking for an experienced E-commerce S...   \n",
       "\n",
       "                                        Resume_clean  \\\n",
       "0  professional resume jason jones jason jones e ...   \n",
       "1  professional resume ann marshall ann marshall ...   \n",
       "2  professional resume patrick mcclain patrick mc...   \n",
       "3  professional resume patricia gray patricia gra...   \n",
       "4  professional resume amanda gross amanda gross ...   \n",
       "\n",
       "                                    Transcript_clean  \\\n",
       "0  interviewer good morning jason great meet welc...   \n",
       "1  interview scene conference room table two chai...   \n",
       "2  interview setting conference room medium sized...   \n",
       "3  simulated professional interview e commerce sp...   \n",
       "4  simulated interview interviewer good morning a...   \n",
       "\n",
       "                               Job_Description_clean  Resume_wordcount  \\\n",
       "0  part passionate team forefront machine learnin...               342   \n",
       "1  help u build next generation product game deve...                51   \n",
       "2  need human resource specialist enhance team te...               405   \n",
       "3  part passionate team forefront cloud computing...               319   \n",
       "4  looking experienced e commerce specialist join...               357   \n",
       "\n",
       "   Resume_clean_wordcount  Transcript_wordcount  Transcript_clean_wordcount  \\\n",
       "0                     264                   606                         339   \n",
       "1                      41                   635                         347   \n",
       "2                     287                   739                         392   \n",
       "3                     241                   843                         490   \n",
       "4                     274                   585                         335   \n",
       "\n",
       "   Job_Description_wordcount  Job_Description_clean_wordcount  \n",
       "0                         22                               13  \n",
       "1                         17                               13  \n",
       "2                         19                               13  \n",
       "3                         22                               13  \n",
       "4                         20                               13  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to preprocess\n",
    "text_columns = ['Resume', 'Transcript', 'Job_Description']\n",
    "\n",
    "# Apply preprocessing\n",
    "df = preprocess_dataframe(df, text_columns)\n",
    "df = add_wordcount_columns(df, text_columns)\n",
    "\n",
    "# Quick check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898569b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"email\"] = df_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75404100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to data/processed/cv_data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Make sure processed folder exists\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "# Save cleaned CSV\n",
    "df.to_csv(\"../data/processed/cv_data_clean.csv\", index=False)\n",
    "print(\"Cleaned data saved to data/processed/cv_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f2de7",
   "metadata": {},
   "source": [
    "# Modeling Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46174d4a",
   "metadata": {},
   "source": [
    "## Embedding Generation\n",
    "\n",
    "### Objective  \n",
    "Transform textual data (CVs and Job Descriptions) into **numerical vector representations** that capture semantic meaning.  \n",
    "These embeddings will later be stored in **Qdrant**, allowing our system to perform **similarity-based retrieval** between job requirements and candidate profiles.\n",
    "\n",
    "### How It Works  \n",
    "- Uses **BERT (Bidirectional Encoder Representations from Transformers)** a deep contextual model trained to understand language semantics.  \n",
    "- Each text (CV or job description) is tokenized, passed through BERT, and converted into a **768-dimensional embedding vector**.  \n",
    "- The **mean pooling** of token embeddings represents the global meaning of the text.  \n",
    "- These embeddings are the foundation of the **matching and ranking logic** in the next stages.\n",
    "\n",
    "### In This Notebook  \n",
    "We call the function `generate_embeddings()` from `embeddings.py` to process two main columns:  \n",
    "- `Resume_clean` â†’ Candidate information.  \n",
    "- `Job_Description_clean` â†’ Job requirements.  \n",
    "\n",
    "The output (`bert_embeddings`) will contain two matrices of shape `(num_texts Ã— 768)` representing both sides of our recruitment problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "from embeddings import generate_embeddings\n",
    "\n",
    "text_columns = ['Resume_clean', 'Job_Description_clean']\n",
    "bert_embeddings = generate_embeddings(df, text_columns, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96bf5350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sayar\\OneDrive\\Desktop\\ai-recruiter-agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BERT embeddings for 'Resume_clean' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:22<00:00,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Resume_clean' embeddings done! Shape: (100, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "from embeddings import generate_embeddings\n",
    "\n",
    "text_columns = ['Resume_clean']\n",
    "bert_embeddings = generate_embeddings(df[:100], text_columns, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9241f661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Resume_clean, Embedding shape: (100, 768)\n",
      "\n",
      "Column: Resume_clean - First 3 embeddings:\n",
      "Index 0: [-0.1221816   0.16356383  0.5868464  -0.13695338  0.3472323   0.01262982\n",
      "  0.25611553  0.06087828 -0.10591841 -0.20190999] ...\n",
      "Index 1: [-0.05073959 -0.11806602  0.27505004  0.0218641   0.09115624 -0.16021815\n",
      "  0.02668428  0.05024377  0.25067604 -0.16618688] ...\n",
      "Index 2: [-0.21807513  0.29017293  0.47447053 -0.19598886  0.38506976 -0.00517338\n",
      "  0.27680123 -0.01751059 -0.08286051 -0.18198432] ...\n"
     ]
    }
   ],
   "source": [
    "# Display shapes of generated embeddings\n",
    "for col, emb in bert_embeddings.items():\n",
    "    print(f\"Column: {col}, Embedding shape: {emb.shape}\")\n",
    "\n",
    "# Display first 3 embeddings for each column\n",
    "for col, emb in bert_embeddings.items():\n",
    "    print(f\"\\nColumn: {col} - First 3 embeddings:\")\n",
    "    for i in range(min(3, len(emb))):\n",
    "        print(f\"Index {i}:\", emb[i][:10], \"...\")  # show first 10 values of each vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc57fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection 'cvs' in Qdrant.\n",
      "Stored 100 CV embeddings in collection 'cvs'.\n"
     ]
    }
   ],
   "source": [
    "from storage import CVStorage\n",
    "\n",
    "storage = CVStorage()\n",
    "storage.add_cv_embeddings(bert_embeddings['Resume_clean'], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691bca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing collection 'cvs' in Qdrant.\n",
      "Retrieved points from Qdrant:\n",
      "\n",
      "CV 0, candidate_id: 0, vector length: 768, first 10 values: [-0.0156574   0.02096048  0.07520354 -0.01755039  0.04449734  0.00161849\n",
      "  0.03282085  0.00780147 -0.0135733  -0.02587448], any NaNs: False\n",
      "CV 1, candidate_id: 1, vector length: 768, first 10 values: [-0.00639109 -0.01487142  0.0346449   0.00275397  0.01148191 -0.02018085\n",
      "  0.00336111  0.00632863  0.03157479 -0.02093266], any NaNs: False\n",
      "CV 2, candidate_id: 2, vector length: 768, first 10 values: [-0.02698374  0.03590483  0.05870907 -0.02425087  0.04764698 -0.00064013\n",
      "  0.03425027 -0.00216669 -0.01025283 -0.02251801], any NaNs: False\n",
      "CV 3, candidate_id: 3, vector length: 768, first 10 values: [-0.01062189  0.0214748   0.06493713 -0.02393205  0.04250755 -0.00113168\n",
      "  0.04098814  0.00662222 -0.00417765 -0.02143684], any NaNs: False\n",
      "CV 4, candidate_id: 4, vector length: 768, first 10 values: [-0.00082673  0.02626257  0.06901769 -0.02630627  0.04887611  0.00089435\n",
      "  0.02572625  0.00610732 -0.02237224 -0.02001831], any NaNs: False\n",
      "CV 5, candidate_id: 5, vector length: 768, first 10 values: [-0.0057187   0.02925331  0.07012111 -0.02491284  0.0404225   0.001485\n",
      "  0.03032763 -0.00393603 -0.00394778 -0.03050126], any NaNs: False\n",
      "CV 6, candidate_id: 6, vector length: 768, first 10 values: [ 0.00238617  0.02482443  0.07988279 -0.02742337  0.04117796 -0.00101451\n",
      "  0.03394507 -0.00731527  0.00120619 -0.03788942], any NaNs: False\n",
      "CV 7, candidate_id: 7, vector length: 768, first 10 values: [-0.01822503  0.04037813  0.06514681 -0.02057613  0.05543352 -0.01572213\n",
      "  0.03504847  0.00933934 -0.0098442  -0.02432706], any NaNs: False\n",
      "CV 8, candidate_id: 8, vector length: 768, first 10 values: [-0.01001316  0.02827188  0.06656446 -0.03221111  0.02849357 -0.0033014\n",
      "  0.03387974  0.0071063  -0.01291356 -0.02450476], any NaNs: False\n",
      "CV 9, candidate_id: 9, vector length: 768, first 10 values: [-0.04475507  0.00977217  0.06357062 -0.01992069  0.03790807  0.00158118\n",
      "  0.01349067  0.00704899 -0.01158442 -0.02674444], any NaNs: False\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from storage import CVStorage\n",
    "import numpy as np\n",
    "\n",
    "# Initialize storage\n",
    "cv_storage = CVStorage(host=\"localhost\", port=6333, collection_name=\"cvs\")\n",
    "\n",
    "# Scroll first 10 points and request vectors back\n",
    "points, next_page = cv_storage.client.scroll(\n",
    "    collection_name=\"cvs\",\n",
    "    limit=10,\n",
    "    with_vectors=True,\n",
    "    with_payload=True,\n",
    ")\n",
    "\n",
    "print(\"Retrieved points from Qdrant:\\n\")\n",
    "\n",
    "def extract_vector(p):\n",
    "    # Single unnamed vector\n",
    "    if getattr(p, \"vector\", None) is not None:\n",
    "        return p.vector\n",
    "    # Named vectors\n",
    "    vs = getattr(p, \"vectors\", None)\n",
    "    if vs is None:\n",
    "        return None\n",
    "    # vs may be dict-like or a VectorStruct with .data\n",
    "    if isinstance(vs, dict):\n",
    "        return vs.get(\"default\") or (next(iter(vs.values())) if vs else None)\n",
    "    data = getattr(vs, \"data\", None)\n",
    "    if isinstance(data, dict):\n",
    "        return data.get(\"default\") or (next(iter(data.values())) if data else None)\n",
    "    return None\n",
    "\n",
    "for i, p in enumerate(points):\n",
    "    vec_raw = extract_vector(p)\n",
    "    if vec_raw is None:\n",
    "        print(f\"CV {i}, candidate_id: {p.payload.get('candidate_id')}, vector is None (not returned).\")\n",
    "        continue\n",
    "    vec = np.asarray(vec_raw, dtype=float)\n",
    "    print(\n",
    "        f\"CV {i}, candidate_id: {p.payload.get('candidate_id')}, \"\n",
    "        f\"vector length: {vec.shape[0]}, first 10 values: {vec[:10]}, any NaNs: {np.isnan(vec).any()}\"\n",
    "    )\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa248c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate 1:\n",
      "ID: 33, Score: 0.7152\n",
      "Resume Text (truncated): professional resume susan edward susan edward quality assurance engineer contact information address 123 main st anytown usa 12345 phone 555 555 5555 email linkedin linkedin com susanedwardsqa profess...\n",
      "Explanation:\n",
      "Susan Edward's resume reveals that she is a highly motivated Quality Assurance Engineer with over five years of professional experience in the software testing field which aligns well with seeking someone for Data Science roles emphasizing on analytical skills required by your job description. Although her primary skill set doesnâ€™t specifically mention Python, machine learning (ML), natural language processing (NLP), or data visualization as presented here, Susan has a proven track record in developing automated tests and performance testing which may suggest experience with the kind of technical troubleshooting that can be related to dealing with ML systems. \n",
      "\n",
      "Here are some highlighted skills from her resume:\n",
      "\n",
      "- Skilled at Selenium, Java, Python (indicating she has programming knowledge)\n",
      "- Experience in test planning and execution using frameworks like TestNG and Selenium WebDriver (showing project experience relevant to software testing processes similar foundational tasks that data science roles might entail such as script development for ML models or automation of NLP pipelines.) \n",
      "- Familiar with JIRA, a bug tracking tool which demonstrates her ability in managing projects and maintaining code quality. (This indicates organizational skills useful when handling complex datasets and iterating through model refinement processes)\n",
      "- Proficient at operating systems like Windows and Linux â€“ an essential skill for ensuring compatibility of diverse software tools often used by data scientists. \n",
      "- Has experience with agile methodology frameworks such as Scrum, Kanban which is beneficial in environments that require quick adaptation to changing datasets or project scopes (a common aspect within the Data Science realm).\n",
      "- Holds a Bachelor's degree from XYZ University and an ISTQB certification showcasing formal education and industry recognition. \n",
      "\n",
      "However, if you are specifically looking for someone with expertise in Python, ML, NLP, or data visualization skills as per your job description, Susan might require some additional training to fill the gap between her current skill set and what is required for a Data Scientist position at your company. Nonetheless, she demonstrates strong analytical mindset through continuous improvement processes which can be vital in any role that requires assessing complex data sets or machine learning model performance. It might also be worthwhile to consider the possibility of cross-training Susan's team with relevant skill development opportunities if her current qualifications were a closer match for your open Data Scientist position.\n",
      "\n",
      "Candidate 2:\n",
      "ID: 99, Score: 0.7064\n",
      "Resume Text (truncated): sample resume machine learning engineer position leah white contact information email phone 555 555 5555 linkedin linkedin com leahwhite github github com leahwhite professional summary highly motivat...\n",
      "Explanation:\n",
      "Leah White is an exceptional candidate for the Data Scientist position due to her extensive experience in Python programming language (Python/R), machine learning frameworks like scikit-learn, TensorFlow, Keras, along with knowledge of data storage manipulation using Pandas and Numpy. She has a strong background in data visualization techniques involving Matplotlib, Seaborn, Plotly as well as deep learning architecture which includes empirical study on image classification published in renowned journals for machine learning research (Journal Machine Learning Research 2020). Leah is also certified with Certified Data Scientist and Scrum Master credentials from respected organizations.\n",
      "\n",
      "In her professional journey, she has been a senior ML Engineer at ABC Corporation wherein she developed predictive maintenance models using TensorFlow scikit learn resulting in a significant 25% reduction of equipment downtime while collaborating with cross-functional teams for integration into production environments and mentored junior engineers to enhance their machine learning skills. Furthermore, Leah has contributed significantly towards the development of data lakes utilizing Apache Hadoop Spark at DEF Startup between 2018 - 2020 where she not only built a real-time recommendation system that increased customer engagement by 15% but also played an integral role in developing ML models and contributing to production environments.\n",
      "\n",
      "Leah's educational credentials include her Master of Science from XYZ University with coursework focused on machine learning, natural language processing (NLP), computer vision as well as a thesis study that dealt specifically with deep learning image classification issues using convolutional neural networks (CNN). This not only emphasizes the depth and breadth of Leah's knowledge in ML technologies but also her ability to apply them practically. Her proficiency extends beyond traditional machine learning techniques, as evidenced by a comparative study on deep learning architecture published recently in an AI research journal (Journal Artific01 2019).\n",
      "\n",
      "In terms of methodology and tools used during projects at her previous workplace include Agile development practices with Scrum frameworks which ensures continuous improvement, efficiency as well as rapid delivery. In addition to this Leah also possesses transfer learning skills that can be very useful in developing robust models for the job role mentioned above.\n",
      "\n",
      "Overall, considering both experience and educational backgrounds along with her professional interests such as passion towards staying up-to-date on latest advancements in ML field it's clear why Leah White would make a significant addition to your team!\n",
      "\n",
      "Candidate 3:\n",
      "ID: 19, Score: 0.7041\n",
      "Resume Text (truncated): sample resume mario edward machine learning engineer candidate mario edward contact information email phone 123 456 7890 linkedin linkedin com marioedwardsml github github com marioedwards professiona...\n",
      "Explanation:\n",
      "This candidate is suitable for the job as they display a wealth of qualifications that align well with what you are seeking:\n",
      "\n",
      "**Experience Relevant to Job Description:**\n",
      "- The resume mentions their role at XYZ Corporation from January 2015 to December 2018, which indicates substantial experience in the field relevant for this Data Scientist position. They held a senior Machine Learning Engineer title and led development of deep learning systems tailored towards ecommerce platforms â€“ an essential skill set that matches your job's data science requirements focusing on Python-based machine learning tasks.\n",
      "\n",
      "**Experience Highlighting Strong Analytical Skills:**\n",
      "- They have experience in deploying scalable, accurate, and efficient ML models using industry-standard frameworks like TensorFlow, PyTorch, Scikit-learn (a well-known library for machine learning), indicating strong analytical skills. These experiences demonstrate their ability to manage complex data science projects that demand robust analysis capabilities â€“ a requirement of your job description.\n",
      "\n",
      "**Experience Indicating Proficiency in NLP and Data Visualization:**\n",
      "- The resume details experience involving the development, evaluation, and implementation of Natural Language Processing systems for sentiment analysis with notable accuracy (90%). This signals strong competencies not just in machine learning but also that they can leverage these skills to derive actionable insights. Though explicit data visualization is not mentioned directly on this resume excerpt, the candidateâ€™s experience aligns well given their demonstrated skill set and professional demeanor as indicated by their mentorship of junior engineers â€“ a role often complemented with presenting findings effectively which may involve reporting insights through various visualization methods.\n",
      "\n",
      "**Skills Demonstrated Align With Job Requirements:**\n",
      "- They are proficient in programming languages such as Python and Java, have experience using machine learning frameworks like TensorFlow and PyTorch along with scikit-learn for deep learning tasks. Knowledge of data manipulation techniques is evidenced by their reference to Pandas (a powerful library used widely amongst Data Scientists), NumPy for numerical operations on large datasets â€“ both crucial skills required in your job description.\n",
      "\n",
      "**Professionalism and Mentorship:**\n",
      "- The resume also indicates that they have mentored junior engineers, highlighting their leadership qualities which are essential when transitioning into a Data Scientist role at an organization like yours where guiding less experienced team members is often part of the job. \n",
      "\n",
      "In summary, given this candidate's solid blend of experience in relevant ML and NLP fields with proven achievements that exceed performance expectations (increased sales by 25%), along with their education from prestigious universities like Stanford University, they appear to be highly suitable for the Data Scientist position you advertised.\n"
     ]
    }
   ],
   "source": [
    "# test_retriever.py\n",
    "\n",
    "import pandas as pd\n",
    "from retriever import CVRetriever\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize Retriever\n",
    "# -----------------------------\n",
    "retriever = CVRetriever(storage=storage, top_k=3)\n",
    "\n",
    "# -----------------------------\n",
    "# Test with a job description\n",
    "# -----------------------------\n",
    "job_desc = \"\"\"\n",
    "Looking for a Data Scientist with experience in Python, ML, NLP, and data visualization.\n",
    "Must have strong analytical skills and 2+ years of industry experience.\n",
    "\"\"\"\n",
    "\n",
    "top_candidates = retriever.retrieve_top_candidates(job_desc)\n",
    "\n",
    "# -----------------------------\n",
    "# Display results\n",
    "# -----------------------------\n",
    "for i, c in enumerate(top_candidates, 1):\n",
    "    print(f\"\\nCandidate {i}:\")\n",
    "    print(f\"ID: {c['candidate_id']}, Score: {c['score']:.4f}\")\n",
    "    print(f\"Resume Text (truncated): {c['cv_text'][:200]}...\")\n",
    "    print(f\"Explanation:\\n{c['explanation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64514a",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4b7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc = \"\"\"\n",
    "Looking for a Data Scientist with experience in Python, ML, NLP, and data visualization.\n",
    "Must have strong analytical skills and 2+ years of industry experience.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae228bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sayar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sayar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "c:\\Users\\sayar\\OneDrive\\Desktop\\ai-recruiter-agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing collection 'cvs' in Qdrant.\n",
      "\n",
      "Graph pipeline:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retrieve] job_vec shape: (768,)\n",
      "[retrieve] search hits: 10\n",
      "[retrieve] kept cvs: 10\n",
      "[analyze] cvs in: 10\n",
      "[analyze] analyzed: 10\n",
      "[rank] ids: 10, embs: 10, job_emb: (768,)\n",
      "[rank] ranking size: 10\n",
      "[rank] top scores: [0.8135, 0.8132, 0.8117]\n",
      "[explain] ranked in: 10, top_k: 5\n",
      "[explain] results: 5\n",
      "5 [(19, 0.8135), (33, 0.8132), (18, 0.8117), (26, 0.8004), (92, 0.8001)]\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "from agentGraph import run_agent_simple, run_agent\n",
    "\n",
    "job_desc = \"\"\"\n",
    "Looking for a Data Scientist with experience in Python, ML, NLP, and data visualization.\n",
    "Must have strong analytical skills and 2+ years of industry experience.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"\\nGraph pipeline:\")\n",
    "res_graph = run_agent(job_desc, top_k=5, with_explain=True)\n",
    "print(len(res_graph), [ (r.get(\"candidate_id\"), round(float(r.get(\"score\", 0.0)), 4)) for r in res_graph ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bc5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 19, Score 0.8135\n",
      "Explanation: The candidate is highly suitable for the Data Scientist position requiring Python ML and NLP expertise as evidenced by his Master's degree in Computer Science from Stanford University where he demonstrated strong analytical abilitiesâ€”an essential requirement of this role. With a proven track record spanning five years, Mario Edward has specialized in developing scalable, accurate, efficient machine learning models using Python and frameworks such as TensorFlow, PyTorch, and Scikit-learn (Deep Learning library), which aligns well with the job description's emphasis on analytical skills.\n",
      "\n",
      "Mario also possesses hands-on experience that matches industry standards for ML roles in data visualizationâ€”a skill demonstrated during his tenure as a senior Machine Learning Engineer at XYZ Corporation, where he led projects delivering deep learning based e-commerce recommendation systems and computer vision defect detection systems with over 95% accuracy. These achievements underscore Mario's ability to handle complex ML algorithms effectively for tangible business improvementsâ€”a key expectation of the position (2018 - Present).\n",
      "\n",
      "His experience at ABC Startup also shows that he understands customer segmentation through natural language processing systems, leading to a 30% improvement in marketing ROI. Mario has not only worked on developing data pipelines but actively participated in code review activities ensuring coding standardsâ€”a trait vital for collaborative work environments as indicated by the job description's mention of SCM methodologies like Kanban and certifications including Certified Data Scientist, further emphasizing his compatibility with industry practices.\n",
      "\n",
      "Finally, Mario has been recognized nationally (Kaggle Competition) and internationally (Amazon Machine Learning Challenge), which demonstrates a consistent high-performance standard he's known to maintain in the field of machine learningâ€”a direct alignment with what is expected from the data scientist position.\n",
      "\n",
      "Overall, Mario Edwardâ€™s unique blend of experience directly matches and exceeds several requirements highlighted by this Data Scientist role description. \n",
      "\n",
      "ID 33, Score 0.8132\n",
      "Explanation: - Concrete Skills: Python programming (Python), Natural Language Processing (NLP) using NLTK or spaCy, proficiency in machine learning frameworks such as scikit-learn or TensorFlow, experience working on data visualization projects with libraries like Matplotlib and Seaborn. Strong analytical skills emphasized throughout the resume align well with this job's requirement for strong analysis capabilities to interpret complex datasets effectively.\n",
      "\n",
      "- Relevant Experience: The candidate has 2 years of industry experience in roles that likely involved similar tasks, such as automated testing using tools like Selenium and Java scripting based on their demonstrated knowledge mentioned earlier. While not directly mentioning data science work, the analytical nature required for quality assurance can translate to interpreting datasets within a machine learning context which is central to this role's responsibilities in developing predictive models or analyzing large amounts of structured and unstructured data.\n",
      "\n",
      "- Alignment with Job Requirements: The candidate has demonstrated proficiency in programming languages such as Java, Python (which was listed along with the company name), suggesting a technical foundation that can be leveraged for machine learning tasks directly related to this job posting's focus on analytical and scripting skills. Though direct data science experience is not mentioned, the emphasis on continuous improvement through process automation implies an understanding of iterative development processes which are critical in agile methodologies often employed by data scientists working with large datasets (a necessity for handling big data).\n",
      "\n",
      "In summary, while Susan Edward's resume does not explicitly state experience as a Data Scientist or related to NLP and ML projects directly within the context of this role, her strong analytical skills in software testing, programming prowess across multiple languages including Pythonâ€”and familiarity with automation tools which might be transferable skill sets for machine learning tasks. Her agile methodology experience could also play a beneficial role when dealing with iterative development and collaboration on complex data science projects commonly found within this field of work as the candidate has demonstrated teamwork, prioritization in bug tracking (testing need), coordination between dev teams which are critical skills for succeeding in such an environment. \n",
      "\n",
      "ID 18, Score 0.8117\n",
      "Explanation: Alejandra Delgado demonstrates a robust fit for the Data Scientist position due to her extensive 5-year experience in UI engineering that has honed her strong analytical abilitiesâ€”a skill set aligned closely with data science'harmonizes well with our requirement of industry expertise. Her proficiency in HTML, React, CSSWireframing coupledwith a comprehensive understandingof UX principles indicates adaptability which can be beneficial when transitioning to data analysis tasks that also require user interface design for presenting findings effectively.\n",
      "\n",
      "Additionally, Alejandra has proven her track record of delivering high-quality solutions and meeting exceeded client expectations as evidenced by increasing user engagement in past rolesâ€”a quality we value highly within our team culture to foster customer satisfaction and retention through data science projects too. Her certification credentials further solidify her capability for this role, particularly the SCM Master Certification which indicates a systematic approach that is essential when managing complex datasets or developing predictive models in Python Machine Learning (ML)and Natural Language Processing (NLP).\n",
      "\n",
      "Alejandra's ability to mentor junior engineers showcases leadership potential and teamworkâ€”a valuable asset for any collaborative data science role. Furthermore, her proactive involvement with industry best practices through design systems is indicative of a commitment towards continuous improvement in skills that can be applied when adopting new tools or techniques within our tech stack related to ML projects.\n",
      "\n",
      "Her educational background at XYZ University where she was awarded for the Best UI Design and led a team creating a recognized industry-standard design system, underlines her ability to innovate while maintaining high standardsâ€”a balance we strive for in data science when crafting compelling visualizations of insights derived from complex analytics.\n",
      "\n",
      "Overall, Alejandra's experience as Senior UI Engineer and Junior engineer at ABC Company demonstrates that she has the blend of technical skills required to succeed in a Data Scientist role with her demonstrated attention to detail, user-centric mindset which is paramount when interpreting data visualizations for stakeholder presentations. She holds relevant certifications indicating formal acknowledgement of these competencies and we recommend including this resume tailored specifically towards the skills required within our organization's Data Scientist role.\n",
      "\n",
      "Good luck to Alejandra in her job search! Her profile stands out as highly suitable for a data scientist position, offering unique skill sets that are complementary both technically and managerially aligned with industry standards of excellence and innovation we pursue within our team's projects related to Python-based Data Science. \n",
      "\n",
      "ID 26, Score 0.8004\n",
      "Explanation: Peter Barron's professional profile indicates a robust background suitable for the Data Scientist position at your company. His Bachelor's in Business Administration from XYZ University provides foundational knowledge which is further complemented by his Certification as both a CBA and CDA, aligning with analytical skills required for data science roles. Peter has 5 years of experience focused on requirement gathering and analyzing business needs â€“ directly connecting to the industry insight aspect sought in your Data Scientist role. Additionally, he possesses proven project management capabilities evidenced by a history of enhancing success rates while effectively managing teams across functions within ABC Corporation. Peter's skill set also includes expertise with Python for ML and NLP projects as well as data visualization techniques using Tableau PBI â€“ fulfilling core technical skills mandated in the job description. Lastly, his professional recognition from an industry institute alongside being a featured speaker at annual conferences showcases Peter's authoritative standing within relevant fields that could bring added value to your business objectives for data-driven decision making and process improvement initiatives. \n",
      "\n",
      "ID 92, Score 0.8001\n",
      "Explanation: James Baldwin's resume demonstrates exceptional qualifications for the Data Scientist position requiring Python, ML/NLP, data visualization, strong analytical skills, as well as two years of industry experience:\n",
      "\n",
      "- Proven expertise in **Python** and other programming languages suggests a versatile skill set.\n",
      "\n",
      "- Extensive background with over five years dedicated to quality assurance (QA) engineering showcases discipline needed for data science roles that rely on precision analysis.\n",
      "\n",
      "- His hands-on experience using the popular **Selenium testing framework leveraging both manual and automated testing** parallels needs in data visualization where precise, repeatable results are essential.\n",
      "\n",
      "- Baldwin's role as a certified Scrum Master aligns with agile methodologies often used within Data Science projects for iterative development processes requiring analytical rigor. \n",
      "\n",
      "- His experience working closely on Agile teams at **ABC Corporation** and involvement in CI/CD pipelines indicate adaptability to fast-paced environments where data science practices are crucial, especially with his focus on ensuring quality software releases which is essential for maintaining the integrity of analytical processes.\n",
      "\n",
      "This blend of technical proficiency across development (like Java and Python) testing frameworks coupled with a robust understanding of Agile methodologies positions James Baldwin as an ideal candidate to excel in data science roles that demand rigorous analysis, quality control, and iterative improvement aligned with industry standards for analytical excellence. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In notebook\n",
    "for r in res_graph:\n",
    "    print(f\"ID {r['candidate_id']}, Score {r['score']:.4f}\")\n",
    "    print(\"Explanation:\", (r.get(\"explanation\") or \"<none>\").strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79bf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing collection 'cvs' in Qdrant.\n",
      "\n",
      "Graph pipeline:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retrieve] job_vec shape: (768,)\n",
      "[retrieve] search hits: 10\n",
      "[retrieve] kept cvs: 10\n",
      "[analyze] cvs in: 10\n",
      "[analyze] analyzed: 10\n",
      "[rank] ids: 10, embs: 10, job_emb: (768,)\n",
      "[rank] ranking size: 10\n",
      "[rank] top scores: [0.8135, 0.8132, 0.8117]\n",
      "[explain] ranked in: 10, top_k: 5\n",
      "[explain] results: 5\n",
      "5 [(19, 0.8135), (33, 0.8132), (18, 0.8117), (26, 0.8004), (92, 0.8001)]\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "from agentGraph import run_agent_simple, run_agent\n",
    "\n",
    "job_desc = \"\"\"\n",
    "Looking for a Data Scientist with experience in Python, ML, NLP, and data visualization.\n",
    "Must have strong analytical skills and 2+ years of industry experience.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"\\nGraph pipeline:\")\n",
    "res_graph = run_agent(job_desc, top_k=5, with_explain=True)\n",
    "print(len(res_graph), [ (r.get(\"candidate_id\"), round(float(r.get(\"score\", 0.0)), 4)) for r in res_graph ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9874c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
